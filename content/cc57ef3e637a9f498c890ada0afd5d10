<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<title>Edge: THE FOURTH QUADRANT: A MAP OF THE LIMITS OF STATISTICS By Nassim Nicholas Taleb</title><style type="text/css">
<!--
a:link {
	color: #000000;
	text-decoration: underline;
}
a:hover {
	color: #EC8D00;
}
a:visited {
	color: #000000;
}
body,td,th {
	font-family: Verdana, Arial, Helvetica, sans-serif;
	text-align: left;
}
.style1 {font-size: 12px}
-->
</style>
</head>

<body>
<div align="center">
  <table width="525"
border="0" align="center">
    <tr valign="top">
      <td height="59"><div align="center"><a name="top" id="top"></a><img src="../../indexelements/banner_thirdculture.gif" width="500" height="50" /></div></td>
    </tr>
  </table>
  <table width="525" border="0" cellspacing="2" cellpadding="0">
    <tr>
      <td height="26" valign="top"><!-- #BeginLibraryItem "/Library/nav bar.Lbi" -->
        <table width="100%" border="1" bgcolor="#666666" bordercolor="#FFFFFF" cellpadding="3" cellspacing="0" align="center" bordercolorlight="#FFFFFF" bordercolordark="#FFFFFF">
          <tr bgcolor="#CCCCCC">
            <td height="20"><div align="center"><font color="#000000" size="1" face="Verdana, Arial, Helvetica, sans-serif"><a href="/"><b>Home</b></a></font></div></td>
            <td height="20"><div align="center"><font color="#000000" size="1" face="Verdana, Arial, Helvetica, sans-serif"><a
href="/about_edge.Html"><b>About Edge</b></a></font></div></td>
            <td height="20"><div align="center"><font face="Verdana, Arial, Helvetica, sans-serif" size="1" color="#000000"><a
href="/archive.Html"><b>Features</b></a> </font></div></td>
            <td height="20"><div align="center"><font face="Verdana, Arial, Helvetica, sans-serif" size="1" color="#000000"><a
href="/documents/archive/edge.Index.Html"><b>Edge Editions</b></a></font></div></td>
            <td height="20"><div align="center"><font face="Verdana, Arial, Helvetica, sans-serif" size="1" color="#000000"><a
href="/edge_news.Html"><b>Press</b></a></font></div></td>
            <td height="20"><div align="center"><font color="#000000" size="1" face="Verdana, Arial, Helvetica, sans-serif"><a href="/search/search.Html"><b>Edge
              Search</b></a></font></div></td>
          </tr>
        </table>
      <!-- #EndLibraryItem --></td>
    </tr>
  </table>
  <hr width="525" size="1" />
  <table width="525" border="0" cellspacing="2" cellpadding="5">
    <tr>
      <td valign="top"><p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em>Statistical and applied probabilistic knowledge is the core of knowledge; statistics is what tells you if something is true, false, or merely anecdotal; it is the &quot;logic of science&quot;; it is the instrument of risk-taking; it is the applied tools of epistemology; you can't be a modern intellectual and not think probabilistically&mdash;but... let's not be suckers. The problem is much more complicated than it seems to the casual, mechanistic user who picked it up in graduate school. Statistics can fool you. In fact it is fooling your government right now. It can even bankrupt the system (let's face it: use of probabilistic methods for the estimation of risks did just blow up the banking system). </em></font></p>
        <p align="left"><strong><font size="2" face="Verdana, Arial, Helvetica, sans-serif">THE FOURTH QUADRANT: A MAP OF THE LIMITS OF STATISTICS </font></strong><font size="1" face="Verdana, Arial, Helvetica, sans-serif"><em>[9.15.08]</em></font><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong><br />
  By Nassim Nicholas Taleb</strong></font></p>
        <p align="left"><strong><font color="#990000" size="2" face="Verdana, Arial, Helvetica, sans-serif">An <em>Edge</em> Original Essay</font></strong></p>
        <p align="center"><strong><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><img src="images/taleb201.jpg" width="150" height="200" /><br />
        </font></strong></p>
        <p align="left"><font face="Verdana, Arial, Helvetica, sans-serif"><strong><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Introduction</font></strong></font><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><br />  
          <br />
          When Nassim Taleb talks about the limits of statistics, he becomes outraged. &quot;My outrage,&quot; he says, &quot;is aimed at the scientist-charlatan putting society at risk using statistical methods. This is similar to iatrogenics, the study of the doctor putting the patient at risk.&quot; As a researcher in probability, he has some credibility. In 2006, using FNMA and bank risk managers as his prime perpetrators, he wrote the following:</font></p>
        <blockquote>
          <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">The government-sponsored institution Fannie Mae, when I look at its risks, seems to be sitting on a barrel of dynamite, vulnerable to the slightest hiccup. But not to worry: their large staff of scientists deemed these events &quot;unlikely.&quot; </font></p>
        </blockquote>
        <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><a href="http://www.amazon.com/Black-Swan-Impact-Highly-Improbable/dp/1400063515/ref=sr_1_1?ie=UTF8&amp;s=books&amp;qid=1221406971&amp;sr=1-1" target="new"><img src="images/blackswan.gif" width="103" height="154" align="right" /></a>In the following <em>Edge </em>original essay, Taleb continues his examination of Black Swans, the highly improbable and unpredictable events that have massive impact. </font><font size="2" face="Verdana, Arial, Helvetica, sans-serif">He claims that those who are putting society at risk are &quot;no true statisticians&quot;, merely people using statistics either without understanding them, or in a self-serving manner.  &quot;The current subprime crisis did wonders to help me drill my point about the limits of statistically driven claims,&quot; he says.</font></p>
        <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Taleb, looking at the cataclysmic situation facing financial institutions today, points out that &quot;the banking system, betting <em>against</em> Black Swans, has lost over 1 Trillion dollars (so far), more than was ever made in the history of banking&quot;.</font></p>
        <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">But, as he points out, there is also good news. </font></p>
        <blockquote>
          <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">We can identify <em>where the danger zone is located</em>, which I call &quot;the fourth quadrant&quot;, and show it on a map with more or less clear boundaries.  A map is a useful thing because you know where you are safe and where your knowledge is questionable. So I drew for the <em>Edge</em> readers a tableau showing the boundaries where statistics works well and where it is questionable or unreliable.  Now once you identify where the danger zone is, where your knowledge is no longer valid, you can easily make some policy rules: how to conduct yourself in that fourth quadrant; what to avoid. </font></p>
        </blockquote>
        <p align="left"> —<font size="2" face="Verdana, Arial, Helvetica, sans-serif"><a href="/3rd_culture/bios/taleb.html">John Brockman</a></font></p>
        <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">NASSIM NICHOLAS TALEB, essayist and former mathematical trader, is Distinguished Professor of Risk Engineering at New York University’s Polytechnic Institute. He is the author of <em>Fooled by Randomness</em> and the international bestseller <em>The Black Swan.</em></font></p>
      <p align="left"><strong><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><a href="/3rd_culture/bios/taleb.html">Nassim Taleb's Edge Bio Page</a></font></strong></p>
      <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong><a href="/discourse/fourth_quadrant.html">REALITY CLUB:</a></strong></font> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">Jaron Lanier, George Dyson</font></p>
      <p align="left"><a href="http://blogsearch.google.com/blogsearch?hl=en&amp;ie=UTF-8&amp;q=link%3Ahttp%3A//www.edge.org/3rd_culture/taleb08/taleb08_index.html&amp;btnG=Search+Blogs" target="new"><font color="#000000" size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong>BLOGWATCH</strong></font></a><font color="#000000" size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong></strong></font></p></td>
    </tr>
  </table>
  <hr width="525" size="1" />
  <table width="525" border="0" align="center" cellpadding="5" cellspacing="2">
    <tr>
      <td valign="top"><p align="left"><strong><font size="2" face="Verdana, Arial, Helvetica, sans-serif">THE FOURTH QUADRANT: A MAP OF THE LIMITS OF STATISTICS<br />
        </font></strong></p>
          <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Statistical and applied probabilistic knowledge is the core
            of knowledge; statistics is what tells you if something is true, false, or
            merely anecdotal; it is the &quot;logic of science&quot;; it is the instrument of
            risk-taking; it is the applied tools of epistemology; you can't be a modern
            intellectual and not think probabilistically—but... let's not be suckers.
            The problem is much more complicated than it seems to the casual, mechanistic
            user who picked it up in graduate school. Statistics can fool you. In fact it
            is fooling your government right now. It can even bankrupt the system (let's
            face it: use of probabilistic methods for the estimation of risks did just <i
style='mso-bidi-font-style:normal'>blow up</i> the banking system).</font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">The current subprime crisis has been doing wonders for the
          reception of any ideas about probability-driven claims in science, particularly
          in social science, economics, and &quot;econometrics&quot; (quantitative economics).<span
style="mso-spacerun: yes">&nbsp; </span>Clearly, with current International
          Monetary Fund estimates of the costs of the 2007-2008 subprime crisis,<span
style="mso-spacerun: yes">&nbsp; </span>the banking system seems to have lost
          more on risk taking (from the failures of quantitative risk management) than
          every penny banks <i style='mso-bidi-font-style:normal'>ever</i> earned
          taking risks. But it was easy to see from the past that the pilot did not have
          the qualifications to fly the plane and was using the wrong navigation tools:
          The same happened in 1983 with money center banks losing cumulatively every
          penny ever made, and in 1991-1992 when the Savings and Loans industry became
          history. </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">It appears that financial institutions earn money on transactions (say
          fees on your mother-in-law's checking account) and lose everything taking risks
          they don't understand. I want this to stop, and stop now— the current
          patching by the banking establishment worldwide is akin to using the same
          doctor to cure the patient when the doctor has a track record of systematically
          killing them. And this is not limited to banking—I generalize to an
          entire class of random variables that do not have the structure we thing they
          have, in which we can be suckers. </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">And we are beyond suckers: not only, for socio-economic
          and other nonlinear, complicated variables, we are riding in a bus driven a blindfolded driver, but we refuse to
          acknowledge it in spite of the evidence, which to me is a pathological problem
          with academia. After 1998, when a &quot;Nobel-crowned&quot; collection of people (and the
          crème de la crème of the financial economics establishment) blew up Long Term
          Capital Management, a hedge fund, because the &quot;scientific&quot; methods they used
          misestimated the role of the rare event, such methodologies and such claims on
          understanding risks of rare events should have been discredited. Yet the Fed
          helped their bailout <i style='mso-bidi-font-style:normal'>and</i> exposure to rare events (and model error) patently increased exponentially (as
          we can see from banks' swelling portfolios of derivatives that we do not
          understand). </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Are we using models of uncertainty to produce certainties? </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">This masquerade does not seem to come from statisticians—but from the commoditized, &quot;me-too&quot; users of the products. Professional
          statisticians can be remarkably introspective and self-critical. Recently, the
          American Statistical Association had a special panel session on the &quot;black
          swan&quot; concept at the annual Joint Statistical Meeting in Denver last August.
          They insistently made a distinction between the &quot;statisticians&quot; (those who deal
          with the subject itself and design the tools and methods) and those in other
          fields who pick up statistical tools from textbooks without really
          understanding them. For them it is a problem with statistical education and
          half-baked expertise. Alas, this category of blind users includes regulators
          and risk managers, whom I accuse of creating more risk than they reduce.<span
style="mso-spacerun: yes">&nbsp; </span></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">So the good news is that we can identify <i style='mso-bidi-font-style:
normal'>where the danger zone is located</i>, which I call &quot;the fourth
          quadrant&quot;, and show it on a map with more or less clear boundaries.<span
style="mso-spacerun: yes">&nbsp; </span>A map is a useful thing because you
          know where you are safe and where your knowledge is questionable. So I drew for
          the <a href="/"><em>Edge</em></a> readers a tableau showing the boundaries where statistics works well
          and where it is questionable or unreliable.<span style="mso-spacerun:
yes">&nbsp; </span>Now once you identify where the danger zone is, where your
          knowledge is no longer valid, you can easily make some policy rules: how to
          conduct yourself in that fourth quadrant; what to avoid.</font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">So the principal value of the map is that it allows for
          policy making. Indeed, I am moving on: my new project is about methods on how
          to domesticate the unknown, exploit randomness, figure out <i style='mso-bidi-font-style:
normal'>how to live in a world we don't understand very well</i>. While
          most human thought (particularly since the enlightenment) has focused us on how
          to turn knowledge into decisions, my new mission is to build methods to turn
          lack of information, lack of understanding, and lack of &quot;knowledge&quot; into
          decisions—how, as we will see, not to be a &quot;turkey&quot;.</font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">This piece has a technical appendix that presents
          mathematical points and empirical evidence. (See link below.) It includes a battery of tests
          showing that no known conventional tool can allow us to make precise
          statistical claims in the Fourth Quadrant. While in the past I limited myself
          to citing research papers, and evidence compiled<span style="mso-spacerun:
yes">&nbsp; </span>by others (a less risky trade), here I got hold of more than
          20 million pieces of data (includes 98% of the corresponding macroeconomics
          values of transacted daily, weekly, and monthly variables for the last 40
          years) and redid a systematic analysis that includes recent years. </font></p>
        <p><strong><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><br />
        What Is Fundamentally Different About Real Life</font></strong><font size="2" face="Verdana, Arial, Helvetica, sans-serif"></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">My anger with &quot;empirical&quot; claims in risk management does not
          come from research. It comes from spending twenty tense (but entertaining)
          years taking risky decisions in the real world managing portfolios of complex
          derivatives, with payoffs that depend on higher order statistical properties
         —and you quickly realize that a certain class of relationships that &quot;look
          good&quot; in research papers almost <i style='mso-bidi-font-style:normal'>never</i> replicate in real life (in spite of the papers making some claims with a &quot;p&quot;
          close to infallible). But that is not the main problem with research. </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">For us the world is vastly simpler in some sense than the
          academy, vastly more complicated in another. So the central lesson from
          decision-making (as opposed to working with data on a computer or bickering
          about logical constructions) is the following: <i style='mso-bidi-font-style:
normal'>it is the exposure (or payoff) that creates the complexity
           —and the opportunities and dangers— not so much the knowledge (
            i.e., statistical distribution, model representation, etc.)</i>. In some
          situations, you can be extremely wrong and be fine, in others you can be
          slightly wrong and explode. If you are leveraged, errors blow you up; if you
          are not, you can enjoy life. </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">So knowledge (i.e., if some statement is &quot;true&quot; or &quot;false&quot;)
          matters little, very little in many situations. In the real world, there are
          very few situations where what you do and your belief if some statement is true
          or false naively map into each other. Some decisions require vastly more
          caution than others—or highly more drastic confidence intervals. For
          instance you do not &quot;need evidence&quot; that the water is poisonous to <i
style='mso-bidi-font-style:normal'><u>not</u></i> drink from it. You do not
          need &quot;evidence&quot; that a gun is loaded to avoid playing Russian roulette, or
          evidence that a thief a on the lookout to lock your door. You need evidence of
          safety—not evidence of lack of safety— a central asymmetry that
          affects us with rare events. This asymmetry in skepticism makes it easy to draw
          a map of danger spots. </font></p>
        <p> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">
            <o:p></o:p>
        <strong><br />
        The Dangers Of Bogus Math</strong></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">I start with my old crusade against &quot;quants&quot;
          (people like me who do mathematical work in finance), economists, and bank risk managers, my
          prime perpetrators of iatrogenic risks (the healer killing the patient). Why
          iatrogenic risks? Because, not only have economists been unable to <i
style='mso-bidi-font-style:normal'>prove that</i> their models work, but
          no one managed to prove that<span style="mso-spacerun: yes">&nbsp; </span>the
          use of a model that does not work is <i style='mso-bidi-font-style:normal'>neutral</i>,
          that it does not increase blind risk taking, hence the accumulation of hidden
          risks.</font></p>
        <p align="center" style='margin-right:2.9pt;tab-stops:441.0pt'> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">
            <o:p>&nbsp;</o:p>
           <img width="271" height="190"
src="images/image002.png">
          </font></p>
        <blockquote>
          <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><strong>Figure
                  <span
style='mso-no-proof:yes'>1</span>
            </strong>My classical metaphor: A Turkey is fed for a
            1000 days—every days confirms to its statistical department that the
            human race cares about its welfare &quot;with increased statistical significance&quot;.
            On the 1001<sup>st</sup> day, the turkey has a surprise.</em></font></p>
        </blockquote>
        <p align="center"> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">
            <o:p>&nbsp;</o:p>
            
            <img width="271" height="244"
src="images/image004.png">
            
          </font></p>
        <blockquote>
          <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><strong>Figure
            <!--[if supportFields]><span style='mso-element:
field-begin'></span><span style="mso-spacerun: yes">&nbsp;</span>SEQ Figure \*
ARABIC <span style='mso-element:field-separator'></span><![endif]-->
                  <span
style='mso-no-proof:yes'>2</span></strong>
            <!--[if supportFields]><span style='mso-element:
field-end'></span><![endif]-->
            The graph above shows the fate of close to 1000
            financial institutions (includes busts such as FNMA,
            Bear Stearns, Northern Rock, Lehman Brothers, etc.). The banking system
            (betting AGAINST rare events) just lost &gt; 1 Trillion dollars (so far) on a
            single error, more than was ever earned in the history of banking. Yet bankers
            kept their previous bonuses and it looks like citizens have to foot the bills.
            And one Professor Ben Bernanke pronounced right before the blowup that we live in an era of stability
            and &quot;great moderation&quot; (he is now piloting a plane and we all are passengers on
            it). </em></font></p>
        </blockquote>
        <p align="center"> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">
            <o:p>&nbsp;</o:p>
            <o:p>&nbsp;</o:p>
            <img width="340" height="255"
src="images/image006.png"> 
          </font></p>
        <blockquote>
          <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><strong>Figure
            
                  <span
style='mso-no-proof:yes'>3</span>
            
            </strong>The graph shows the daily variations a
            derivatives portfolio exposed to U.K. interest rates between 1988 and 2008.
            Close to 99% of the variations, over the span of 20 years, will be represented
            in 1 single day—the day the European Monetary System collapsed. As I
            show in the appendix, this is typical with ANY socio-economic variable
            (commodity prices, currencies, inflation numbers, GDP, company performance,
            etc. ). No known econometric statistical method can capture the probability of
            the event with any remotely acceptable accuracy (except, of course, in
            hindsight, and &quot;on paper&quot;). Also note that this applies to surges on
            electricity grids and all manner of modern-day phenomena.</em></font></p>
        </blockquote>
        <p> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">
            <o:p></o:p>
          Figures 1 and 2 show you the classical problem of the turkey
          making statements on the risks based on past history (mixed with some
          theorizing that happens to narrate well with the data). A friend of mine was
          sold a package of subprime loans (leveraged) on grounds that &quot;30 years of
          history show that the trade is safe.&quot; He found the argument unassailable
          &quot;empirically&quot;. And the unusual dominance of the rare event shown in Figure 3 is
          not unique: it affects <em>all </em>macroeconomic data—if you look long enough
          almost <em>all </em>the contribution in some classes of variables will come from rare
          events (I looked in the appendix at 98% of trade-weighted data). </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Now let me tell you what worries me. Imagine that the Turkey
          can be the most powerful man in world economics, managing our economic fates.
          How? <span style='mso-fareast-font-family:&quot;Times New Roman&quot;;mso-fareast-theme-font:
minor-fareast'>A then-Princeton economist called Ben Bernanke made a
            pronouncement in late 2004 about the &quot;new moderation&quot; in economic life: the
            world getting more and more stable—before becoming the Chairman of the
            Federal Reserve. Yet the system was getting riskier and riskier as we were
            turkey-style sitting on more and more barrels of dynamite—and Prof.
            Bernanke's predecessor the former Federal Reserve Chairman Alan Greenspan was
            systematically increasing the hidden risks in the system, making us all more
          vulnerable to blowups. </span></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">By the &quot;narrative fallacy&quot; the turkey economics
          department will always manage to state, before thanksgivings that &quot;we are in a
          new era of safety&quot;, and back-it up with thorough and &quot;rigorous&quot; analysis. And
          Professor Bernanke indeed found plenty of economic explanations—what I
          call the narrative fallacy—with graphs, jargon, curves, the kind of
          facade-of-knowledge that you find in economics textbooks. (This is the find of
          glib, snake-oil facade of knowledge—even more dangerous because of the
          mathematics—that made me, before accepting the new position in NYU's
          engineering department, verify that there was not a single economist in the
          building. I have nothing against economists: you should let them entertain each
          others with their theories and elegant mathematics, and help keep college
          students inside buildings. But beware: they can be plain wrong, yet frame things in a way to make you feel stupid arguing with them. So  make sure you do not give any of them
          risk-management responsibilities.)</font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong><br />
        Bottom Line: The Map</strong></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Things are made simple by the following. There are two <i
style='mso-bidi-font-style:normal'>distinct</i> types of decisions, and
          two <i style='mso-bidi-font-style:normal'>distinct</i> classes of
          randomness. </font></p>
        <p style='margin-right:2.9pt;tab-stops:441.0pt'><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><b
style='mso-bidi-font-weight:normal'>Decisions</b>: The first type of decisions
          is simple, &quot;binary&quot;, i.e. you just care if something is true or false. Very
          true or very false does not matter. Someone is either pregnant or not pregnant.
          A statement is &quot;true&quot; or &quot;false&quot; with some confidence interval. (I call these
          M0 as, more technically, they depend on the zero<sup>th</sup> moment, namely just on probability of events, and not their magnitude
         —you just care about &quot;raw&quot; probability). A biological experiment in the
          laboratory or a bet with a friend about the outcome of a soccer game belong to
          this category.</font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">The second type of decisions is more complex. You do not
          just care of the frequency—but of the impact as well, or, even more
          complex, some function of the impact. So there is another layer of uncertainty
          of impact. (I call these M1+, as they depend on higher moments of the
          distribution). When you invest you do not care how many times you make or lose,
          you care about the expectation: how many times you make or lose <i
style='mso-bidi-font-style:normal'>times</i> the amount made or lost. </font></p>
        <p style='margin-right:2.9pt;tab-stops:441.0pt'><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><b
style='mso-bidi-font-weight:normal'>Probability structures</b>: There are two
          classes of probability domains—very distinct qualitatively and
          quantitatively. The first, thin-tailed: Mediocristan&quot;,
          the second, thick tailed Extremistan. Before I get
          into the details, take the literary distinction as follows: </font></p>
        <p style='margin-right:2.9pt;tab-stops:441.0pt'><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><i
style='mso-bidi-font-style:normal'>In Mediocristan,
          exceptions occur but don't carry large consequences. Add the heaviest person on
          the planet to a sample of 1000. The total weight would barely change. In Extremistan, exceptions can be everything (they will
          eventually, in time, represent everything). Add Bill Gates to your sample: the
          wealth will<span style="mso-spacerun: yes">&nbsp; </span>jump by a factor of
          &gt;100,000.</i> So, in Mediocristan, large
          deviations occur but they are not consequential—unlike Extremistan.</font></p>
        <p style='margin-right:2.9pt;tab-stops:441.0pt'><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Mediocristan corresponds to &quot;random walk&quot; style randomness
          that you tend to find in regular textbooks (and in popular books on
          randomness). Extremistan corresponds to a &quot;random
          jump&quot; one. The first kind I can call &quot;Gaussian-Poisson&quot;,
          the second &quot;fractal&quot; or Mandelbrotian (after the
          works of the great Benoit Mandelbrot linking it to the geometry of nature). But
          note here an epistemological question: there is a category of &quot;I don't know&quot;
          that I also bundle in Extremistan for the sake of
          decision making—simply because I don't know much about the probabilistic
          structure or the role of large events.<i style='mso-bidi-font-style:normal'>
                <o:p></o:p>
              </i></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><b><br />
        The Map</b></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Now it
        lets see where the traps are:</font></p>
        <blockquote>
          <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">First Quadrant: Simple binary
            decisions, in Mediocristan: Statistics does wonders.
            These situations are, unfortunately, more common in academia, laboratories, and
            games than real life—what I call the &quot;ludic fallacy&quot;. In other words, these are the situations in casinos, games, dice, and
            we tend to study them because we are successful in modeling them. </span></font></p>
          <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Second Quadrant: Simple decisions,
            in Extremistan: some well known problem studied in
            the literature. Except of course that there are not many simple decisions in Extremistan.</font><br />
            <br />
            <font size="2" face="Verdana, Arial, Helvetica, sans-serif">Third Quadrant: Complex decisions
            in Mediocristan: Statistical methods work
            surprisingly well.</font><br />
            <br />
            <font size="2" face="Verdana, Arial, Helvetica, sans-serif"><b style='mso-bidi-font-weight:
normal'>Fourth Quadrant</b>: Complex decisions in Extremistan:
            Welcome to the Black Swan domain. Here is where your limits are. Do not base
            your decisions on statistically based claims. Or, alternatively, try to move
          your exposure type to make it third-quadrant style (&quot;clipping tails&quot;).</font></p>
            </blockquote>
        <div align="center">
            <p style="text-align:center;page-break-after:avoid"> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">
              <o:p></o:p>
            <img src="images/1.jpg" width="520" height="439" /></font></p>
          <div align="left">
              <blockquote>
                <p><font size="2"><span style="text-align:left;page-break-after:avoid"><font face="Verdana, Arial, Helvetica, sans-serif"><em>The four quadrants. The South-East area (in orange) is
                  where statistics and models fail us. </em></font></span></font><br />
                  <br />
                </p>
              </blockquote>
            <p><font size="2"><span style="text-align:center;page-break-after:avoid"><font face="Verdana, Arial, Helvetica, sans-serif"><strong>Tableau Of Payoffs</strong></font></span></font></p>
          </div>
        </div>
        <div align="center">
            <p><img src="images/2.jpg" width="430" height="1012" /></p>
        </div>
        <div align="left">
          <p><font size="2"><strong><font face="Verdana, Arial, Helvetica, sans-serif"><br />
          Two Difficulties</font></strong></font></p>
        </div>
        <p style='margin-right:2.9pt;tab-stops:441.0pt'><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Let me refine
          the analysis. The passage from theory to the real world presents two distinct
        difficulties: &quot;inverse problems&quot; and<span style="mso-spacerun: yes">&nbsp; </span>&quot;pre-asymptotics&quot;.</font></p>
        <blockquote>
          <p style="margin-right:2.9pt;tab-stops:441.0pt"><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong>Inverse Problems.</strong> It is the greatest epistemological difficulty I know. In real life we do not observe probability distributions (not even in Soviet Russia, not even the French government). We just observe events. So we do not know the statistical properties—until, of course, after the fact. Given a set of observations, plenty of statistical distributions can correspond to the exact same realizations—each would extrapolate differently outside the set of events on which it was derived. The inverse problem is more acute when more theories, more distributions can fit a set a data. </font></p>
          <p style="margin-right:2.9pt;tab-stops:441.0pt"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">This inverse problem is compounded
            by the small sample properties of rare events as these will be naturally rare
            in a past sample. It is also acute in the presence of nonlinearities as the
            families of possible models/parametrization explode
            in numbers. </font></p>
          <p style="margin-right:2.9pt; tab-stops:441.0pt; margin-bottom: 6.0pt;"><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><b style='mso-bidi-font-weight:
normal'>Pre-asymptotics</b>. Theories are, of
            course, bad, but they can be worse in some situations when they were derived in
            idealized situations, the asymptote, but are used outside the asymptote (its
            limit, say infinity or the infinitesimal). Some asymptotic properties do work
            well preasymptotically (Mediocristan),
            which is why casinos do well, but others do not, particularly when it comes to Extremistan.</font></p>
          <p style="margin-right:2.9pt;tab-stops:441.0pt"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Most statistical
            education is based on these asymptotic, Platonic properties—yet we live
            in the real world that rarely resembles the asymptote.<span
style="mso-spacerun: yes">&nbsp; </span>Furthermore, this compounds the ludic fallacy: most of what students of statistics do is
            assume a structure, typically with a known probability. Yet the problem we have
            is not so much making computations once you know the probabilities, but finding
            the true distribution.</font><br />
            <br />
          </p>
        </blockquote>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong>The Inverse Problem Of The Rare Events</strong></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Let us start with the inverse problem of rare events and proceed
          with a simple, nonmathematical argument. In August 2007, <em>The Wall Street
          Journa</em>l published a statement by one financial economist, expressing his
          surprise that financial markets experienced a string of events that &quot;would
          happen once in 10,000 years&quot;. A portrait of the gentleman accompanying the
          article revealed that he was considerably&nbsp; younger than 10,000 years; it
          is therefore fair to assume that he was not drawing his inference from his own
          empirical experience (and not from history at large), but from some theoretical
          model that produces the risk of rare events, or what he perceived to be rare
          events. </font></p>
        <p style='margin-right:2.9pt;tab-stops:441.0pt'><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Alas, the rarer
          the event, the more theory you need (since we don't observe it). So <i
style='mso-bidi-font-style:normal'>the rarer the event, the worse its
            inverse problem</i>. And theories are fragile (just think of Doctor
          Bernanke). </font></p>
        <p style='margin-right:2.9pt;tab-stops:441.0pt'><font size="2" face="Verdana, Arial, Helvetica, sans-serif">The tragedy is as follows. Suppose that you are deriving
          probabilities of future occurrences from the data, assuming (generously) that
          the past is representative of the future. Now, say that you estimate that an
          event happens every 1,000 days. You will need a lot more data than 1,000 days
          to ascertain its frequency, say 3,000 days. Now, what if the event happens once
          every 5,000 days? The estimation of this probability requires some larger
          number, 15,000 or more. The smaller the probability, the more observations you
          need, and the greater the estimation error for a set number of observations.
          Therefore, to estimate a rare event you need a sample that is larger and larger
          in inverse proportion to the occurrence of the event.
          <o:p></o:p>
          </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><i style='mso-bidi-font-style:normal'><span
style='mso-fareast-font-family:SimSun'>If small probability events carry large
          impacts, and (at the same time) these small probability events are more
          difficult to compute from past data itself</span></i><span style='mso-fareast-font-family:
SimSun'>, then: our empirical knowledge about the potential contribution—or role—of rare events (probability &times; consequence) is
            inversely proportional to their impact. This is why we should worry in the
            fourth quadrant!
            <o:p></o:p>
              </span></font></p>
        <p style='margin-right:2.9pt;tab-stops:441.0pt'><font size="2" face="Verdana, Arial, Helvetica, sans-serif">For rare
          events, the confirmation bias (the tendency, Bernanke-style, of finding samples
          that confirm your opinion, not those that disconfirm it) is very costly and
          very distorting. Why? Most of histories of Black Swan prone events is going to
          be Black Swan free! Most samples will not reveal the black swans—except
          after if you are hit with them, in which case you will not be in a position to
          discuss them. Indeed I show with 40 years of data that past Black Swans <i
style='mso-bidi-font-style:normal'>do not</i> predict future Black Swans
          in socio-economic life.</font></p>
        <p align="center" style='margin-right:2.9pt;tab-stops:441.0pt'> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">
            <o:p>&nbsp;</o:p>
           
            <img width="224" height="159"
src="images/image008.png">
            
          </font></p>
        <blockquote>
          <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><strong>Figure
           
                  <span
style='mso-no-proof:yes'>4</span></strong>
            
            The
            Confirmation Bias At Work. For left-tailed fat-tailed distributions, we do
            not see much of negative outcomes for surviving entities AND we have a small sample in the left tail. This is why we tend to
            see a better past for a certain class of time series than warranted. </em></font></p>
        </blockquote>
        <p style='margin-right:2.9pt;tab-stops:441.0pt'> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">
            <o:p></o:p>
        <strong><br />
        Fallacy Of The Single Event Probability</strong></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Let us look at events in Mediocristan. <span style='mso-fareast-font-family:&quot;Times New Roman&quot;;mso-fareast-theme-font:
minor-fareast'>In a developed country a newborn female</span> <span style='mso-fareast-font-family:&quot;Times New Roman&quot;;
mso-fareast-theme-font:minor-fareast'>is expected to die at around 79,
          according to insurance tables. When she</span> <span style='mso-fareast-font-family:&quot;Times New Roman&quot;;mso-fareast-theme-font:
minor-fareast'>reaches her 79th birthday, her life expectancy, assuming that
            she is in typical health, is another 10 years. At the age of 90, she should
            have another</span> <span style='mso-fareast-font-family:
&quot;Times New Roman&quot;;mso-fareast-theme-font:minor-fareast'>4.7 years to go. </span>So
          if you are told that a person is older than 100, you can estimate that he is
          102.5 and conditional on the person being older than 140 you can estimate that
          he is 140 plus a few minutes. <span style='mso-fareast-font-family:&quot;Times New Roman&quot;;
mso-fareast-theme-font:minor-fareast'>The conditional expectation of additional</span> <span style='mso-fareast-font-family:&quot;Times New Roman&quot;;
mso-fareast-theme-font:minor-fareast'>life drops as a person gets older.</span><span
style='mso-fareast-font-family:&quot;Times New Roman&quot;;mso-fareast-theme-font: minor-fareast'>
                <o:p></o:p>
              </span></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">In Extremistan things work differently and the conditional expectation of an increase in a random variable does not drop as the variable gets larger. In the real world, say with stock returns (and all economic variable), conditional on a loss being worse than the 5 units, to use a conventional unit of measure units, it will be around 8 units. Conditional that a move is more than 50 STD it should be around 80 units, and if we go all the way until the sample is depleted, the average move worse than 100 units is 250 units! This extends all the way to areas in which we have sufficient sample.<br />
          <br />
        This tells us that there is &quot;no typical&quot; failure and &quot;no typical&quot; success.  You may be able to predict the occurrence of a war, but you will not be able to gauge its effect! Conditional on a war killing more than 5 million people, it should kill around 10 (or more). Conditional on it killing more than 500 million, it would kill a billion (or more, we don't know).  You may correctly predict a skilled person getting &quot;rich&quot;, but he can make a million, ten million, a billion, ten billion—there is no typical number. We have data, for instance, for predictions of drug sales, conditional on getting things right. Sales estimates are totally uncorrelated to actual sales—some drugs that were correctly predicted to be successful had their sales underestimated by up to 22 times!</font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">This absence of &quot;typical&quot; event in Extremistan is what makes prediction markets ludicrous, as they make events look binary. &quot;A
          war&quot; is meaningless: you need to estimate its damage—and no damage is
          typical. Many predicted that the First War would occur—but nobody
          predicted its magnitude. Of the reasons economics does not work is that the
          literature is almost completely blind to the point.</font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong><br />
        A Simple Proof Of Unpredictability In The Fourth Quadrant</strong></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">I show elsewhere that if you don't know what a &quot;typical&quot;
          event is, fractal power laws are the most effective way to <i style='mso-bidi-font-style:
normal'>discuss</i> the extremes mathematically. It does not mean that the real
          world generator is actually a power law—it means you don't understand
          the structure of the external events it delivers and
          need a tool of analysis so you do not become a turkey. Also, fractals simplify
          the mathematical discussions because all you need is play with one parameter (I
          call it &quot;alpha&quot;) and it increases or decreases the role of the rare event in
          the total properties. </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">For instance, you move alpha from 2.3 to 2 in the
          publishing business, and the sales of books in excess of 1 million copies
          triple!<span style="mso-spacerun: yes">&nbsp; </span>Before meeting Benoit
          Mandelbrot, I used to play with combinations of scenarios with series of
          probabilities and series of payoffs filling spreadsheets with clumsy
          simulations; learning to use fractals made such analyses immediate. Now all I
          do is change the alpha and see what's going on.</font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Now the problem: <i style='mso-bidi-font-style:
normal'>Parametrizing</i><i style='mso-bidi-font-style:normal'> a power law lends itself to monstrous estimation errors</i> (I said that
          heavy tails have horrible inverse problems). Small changes in the &quot;alpha&quot; main
          parameter used by power laws leads to monstrously large effects in the tails. Monstrous.</font></p>
        <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">And we don't observe the &quot;alpha. Figure 5 shows more than 40
          thousand computations of the tail exponent &quot;alpha&quot; from different samples of
          different economic variables (data for which it is impossible to refute fractal
          power laws). We clearly have problems figuring it what the &quot;alpha&quot; is: our
          results are marred with errors. Clearly the mean absolute error is in excess of
          1 (i.e. between alpha=2 and alpha=3). Numerous papers in econophysics found an &quot;average&quot; alpha between 2 and 3—but if you process the &gt;20
          million pieces of data analyzed in the literature, you find that the variations
          between single variables are extremely significant.<br />
                <br />
          </font></p>
        <p align="center"><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><span style="text-align:center;page-break-after:avoid"><img width="302" height="187"
src="images/image010.png" align="center" hspace="9"></span></font></p>
        <blockquote>
          <p style="text-align:left;page-break-after:avoid"><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><strong>Figure
            
                  <span
style='mso-no-proof:yes'>5</span></strong><span
style='mso-no-proof:yes'>—</span>Estimation error in &quot;alpha&quot; from 40 thousand
            economic variables. I thank Pallop Angsupun for data.<br />
            </em></font></p>
        </blockquote>
        <p style="text-align:left;page-break-after:avoid"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Now this mean error has massive consequences. Figure 6 shows
          the effect: the expected value of your losses in excess of a certain
          amount(called &quot;shortfall&quot;) is multiplied by &gt;10 from a small change in the
          &quot;alpha&quot; that is less than its mean error! These are the losses banks were
          talking about with confident precision!</font></p>
        <p align="center"> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">
            
            <img width="362" height="224"
src="images//image012.png">
            
          </font></p>
        <blockquote>
          <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><strong>Figure
            
                  <span
style='mso-no-proof:yes'>6</span></strong>—The value of the expected shortfall
            (expected losses in excess of a certain threshold) in response to changes in
            tail exponent &quot;alpha&quot;. We can see it explode by an order of magnitude.</em></font></p>
        </blockquote>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">What if the distribution is not a power law? This is a
          question I used to get once a day. Let me repeat it: my argument would not
          change—it would take longer to phrase it. </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Many researchers, such as Philip Tetlock,
          have looked into the incapacity of social scientists in forecasting
          (economists, political scientists). It is thus evident that while the
          forecasters might be just &quot;empty suits&quot;, the forecast errors are dominated by
          rare events, and we are limited in our ability to track them. The &quot;wisdom of
          crowds&quot; might work in the first three quadrant; but it certainly fails (and has
          failed) in the fourth.</font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong><br />
        Living In The Fourth Quadrant</strong></font></p>
        <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong><em>Beware the Charlatan.</em></strong> <span style='mso-fareast-font-family:&quot;Times New Roman&quot;;mso-fareast-theme-font:
minor-fareast'>When I was a quant-trader in complex derivatives, people
          mistaking my profession used to ask me for &quot;stock tips&quot; which put me in a state
          of rage: a charlatan is someone likely (statistically) to give you positive
          advice, of the &quot;how to&quot; variety.
              <o:p></o:p>
        </span></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Go to a bookstore, and look at the
          business shelves: you will find plenty of books telling you how to make your
          first million, or your first quarter-billion, etc. You will not be likely to
          find a book on &quot;how I failed in business and in life&quot;—though the second
          type of advice is vastly more informational, and typically less charlatanic.
          Indeed, the only popular such finance book I found that was not quacky in nature—on how someone lost his fortune—was both self-published and out of print. Even in academia, there is
          little room for promotion by publishing negative results—though these,
          are vastly informational and less marred with statistical biases of the kind we
          call data snooping. So all I am saying is &quot;what is it that <i style='mso-bidi-font-style:normal'>we don't know</i>&quot;, and my
          advice is what to avoid, no more.
          <o:p></o:p>
        </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">You can live longer if you avoid death,
          get better if you avoid bankruptcy, and become prosperous if you avoid blowups
          in the fourth quadrant.
          <o:p></o:p>
          </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Now you would think that people would buy
          my arguments about lack of knowledge and accept unpredictability. But many kept
          asking me &quot;now that you say that our measures are wrong, do you have anything
        better?&quot;<span style="mso-spacerun: yes">&nbsp; </span></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">I used to give the same
          mathematical finance lectures for both graduate students and practitioners
          before giving up on academic students and grade-seekers. Students cannot
          understand the value of &quot;this is what we don't know&quot;—they think it is <i
style='mso-bidi-font-style:normal'>not</i> information, that they are learning
          nothing. Practitioners on the other hand value it immensely. Likewise with
          statisticians: I never had a disagreement with statisticians (who build the
          field)—only with users of statistical methods.
          <o:p></o:p>
                  </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Spyros Makridakis and I are editors of a special issue of a decision science journal, <i
style='mso-bidi-font-style:normal'>The International Journal of Forecasting</i>.
          The issue is about &quot;What to do in an environment of low predictability&quot;. We
          received tons of papers, but guess what? Very few addressed the point: they
          mostly focused on showing us that they predict better (on paper).<span
style="mso-spacerun: yes">&nbsp; </span>This convinced me to engage in my new
          project: &quot;how to live in a world we don't understand&quot;.
          <o:p></o:p>
          </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif">So for now I can produce phronetic rules (in the Aristotelian sense of <i style='mso-bidi-font-style:normal'>phronesis</i>,
          decision-making wisdom).<span style="mso-spacerun: yes">&nbsp;</span>Here are
          a few, to conclude.
          <o:p></o:p>
        </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><b style='mso-bidi-font-weight:
normal'><span style="mso-fareast-font-family:&quot;Times New Roman&quot;;mso-fareast-theme-font:
minor-fareast"><br />
          Phronetic Rules: What Is Wise To Do (Or Not Do) In The Fourth Quadrant</span></b> </font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong>1) Avoid Optimization, Learn to Love Redundancy. </strong> Psychologists tell us that getting rich does not bring happiness—if you spend it. But if you hide it under the mattress, you are less vulnerable to a black swan. Only fools (such as Banks) optimize, not realizing that a simple model error can blow through their capital (as it just did). In one day in August 2007, Goldman Sachs experienced 24 x the average daily transaction volume—would 29 times have blown up the system? The only weak point I know of financial markets is their ability to drive people &amp; companies to &quot;efficiency&quot; (to please a stock analyst’s earnings target) against risks of extreme events.<br />
          <br />
          Indeed some systems tend to optimize—therefore become more fragile. Electricity grids for example optimize to the point of not coping with unexpected surges—Albert-Lazlo Barabasi warned us of the possibility of a NYC blackout like the one we had in August 2003. Quite prophetic, the fellow. Yet energy supply kept getting more and more efficient since. Commodity prices can double on a short burst in demand (oil, copper, wheat) —we no longer have any slack.  Almost everyone who talks about &quot;flat earth&quot; does not realize that it is overoptimized to the point of maximal vulnerability. <br />
          <br />
          Biological systems—those that survived millions of years—include huge redundancies. Just consider why we like sexual encounters (so redundant to do it so often!). Historically populations tended to produced around 4-12 children to get to the historical average of ~2 survivors to adulthood. <br />
          <br />
          Option-theoretic analysis: redundancy is like long an option. You certainly pay for it, but it may be necessary for survival.<br />
          <br />
          <strong>2) Avoid prediction of remote payoffs</strong>—though not necessarily ordinary ones. Payoffs from remote parts of the distribution are more difficult to predict than closer parts.<br />
          <br />
          A general principle is that, while in the first three quadrants you can use the best model you can find, this is dangerous in the fourth quadrant: no model should be better than just any model.<br />
          <br />
          <strong>3) Beware the &quot;atypicality&quot; of remote events.</strong> There is a sucker's method called &quot;scenario analysis&quot; and &quot;stress testing&quot;—usually based on the past (or some &quot;make sense&quot; theory). Yet I show in the appendix how past shortfalls that do not predict subsequent shortfalls. Likewise, &quot;prediction markets&quot; are for fools. They might work for a binary election, but not in the Fourth Quadrant. Recall the very definition of events is complicated: success might mean one million in the bank ...or five billions!<br />
          <br />
          <strong>4) Time. </strong>It takes much, much longer for a times series in the Fourth Quadrant to reveal its property. At the worst, we don't know how long. Yet compensation for bank executives is done on a short term window, causing a mismatch between observation window and necessary window. They get rich in spite of negative returns. But we can have a pretty clear idea if the &quot;Black Swan&quot; can hit on the left (losses) or on the right (profits).<br />
          <br />
          The point can be used in climatic analysis. Things that have worked for a long time are preferable—they are more likely to have reached their ergodic states.<br />
          <strong><br />
          5) Beware Moral Hazard.</strong> Is optimal to make series of bonuses betting on hidden risks in the Fourth Quadrant, then blow up and write a thank you letter. Fannie Mae and Freddie Mac's Chairmen will in all likelihood keep their previous bonuses (as in all previous cases) and even get close to 15 million of severance pay each.<br />
          <br />
          <strong>6) Metrics.</strong> Conventional metrics based on type 1 randomness don't work. Words like &quot;standard deviation&quot; are not stable and does not measure anything in the Fourth Quadrant. So does &quot;linear regression&quot; (the errors are in the fourth quadrant), &quot;Sharpe ratio&quot;, Markowitz optimal portfolio, ANOVA shmnamova, Least square, etc. Literally anything mechanistically pulled out of a statistical textbook.<br />
          <br />
          My problem is that people can both accept the role of rare events, agree with me, <em>and</em> still use these metrics, which is leading me to test if this is a psychological disorder.  <br />
          <br />
          The technical appendix shows why these metrics fail: they are based on &quot;variance&quot;/&quot;standard deviation&quot; and terms invented years ago when we had no computers. </font><font size="2" face="Verdana, Arial, Helvetica, sans-serif">One way I can prove that anything linked to standard deviation is a facade of knowledge: There is a measure called Kurtosis that indicates departure from &quot;Normality&quot;. It is very, very unstable and marred with huge sampling error: 70-90% of the Kurtosis in Oil, SP500, Silver, UK interest rates, Nikkei, US deposit rates, sugar, and the dollar/yet currency rate come from 1 day in the past 40 years, reminiscent of figure 3. This means that no sample will ever deliver the true variance. It also tells us anyone using &quot;variance&quot; or &quot;standard deviation&quot; (or worse making models that make us take decisions based on it) in the fourth quadrant is incompetent.<br />
          <br />
          <strong>7) Where is the skewness? </strong> Clearly the Fourth Quadrant can present left or right skewness. If we suspect right-skewness, the true mean is more likely to be underestimated by measurement of past realizations, and the total potential is likewise poorly gauged. A biotech company (usually) faces positive uncertainty, a bank faces almost exclusively negative shocks. I call that in my new project &quot;concave&quot; or &quot;convex&quot; to model error.</font></p>
        <p align="center" style='text-align:center'><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><span
style='mso-fareast-font-family:&quot;Times New Roman&quot;;mso-fareast-theme-font:minor-fareast;
mso-no-proof:yes'>
            
            <img width="486" height="231"
src="images//image014.png">
           
            </span><span
style='mso-fareast-font-family:&quot;Times New Roman&quot;;mso-fareast-theme-font:minor-fareast'>
            <o:p></o:p>
          </span></font></p>
        <p><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong>8) Do not confuse absence of volatility with absence of risks.</strong> Recall how conventional metrics of using volatility as an indicator of stability has fooled Bernanke—as well as the banking system.</font></p>
        <p align="center"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">
          <o:p></o:p>
        </font><font size="2" face="Verdana, Arial, Helvetica, sans-serif">
            <img width="326" height="202"
src="images//image016.png">
            
                </font></p>
        <blockquote>
          <p style='text-align:justify'><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><strong>Figure
            
                  <span
style='mso-no-proof:yes'>7</span></strong>
           
            Random Walk—Characterized by volatility. You
            only find these in textbooks and in essays on probability by people who have
          never really taken decisions under uncertainty.</em></font><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><span style='mso-fareast-font-family:
&quot;Times New Roman&quot;;mso-fareast-theme-font:minor-fareast'>
          <o:p></o:p>
          </span>
          <o:p></o:p>
          </em></font><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em>
          <o:p></o:p>
          </em></font></p>
        </blockquote>
        <p align="center"> <font size="2" face="Verdana, Arial, Helvetica, sans-serif">
            <o:p>&nbsp;</o:p>

            
            <img width="326" height="202"
src="images//image018.png">
            
            <br />
          </font></p>
        <blockquote>
          <p style='text-align:justify'><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><strong>Figure
            
                  <span
style='mso-no-proof:yes'>8</span></strong>
          
            Random Jump process—It is not characterized by
            its volatility. Its exits the 80-120 range much less often, but its extremes
          are far more severe. Please tell Bernanke if you have the chance to meet him.</em></font><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><em><span
style='mso-fareast-font-family:&quot;Times New Roman&quot;;mso-fareast-theme-font:minor-fareast'>
          <o:p></o:p>
          </span></em></font><font size="2" face="Verdana, Arial, Helvetica, sans-serif">
          <o:p></o:p>
          </font> </p>
        </blockquote>
        <p style="tab-stops:185.6pt"><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><span style='mso-fareast-font-family:
&quot;Times New Roman&quot;;mso-fareast-theme-font:minor-fareast'><strong>9) Beware presentations of risk numbers.</strong> Not only we have mathematical
          problems, but risk perception is subjected to framing issues that are acute in
          the Fourth Quadrant. </span>Dan Goldstein and I are running a program of
          experiments in the psychology of uncertainty and finding that the perception of
          rare events is subjected to severe framing distortions: people are aggressive
          with risks that hit them &quot;once every thirty years&quot; but not if they are told
          that the risk happens with a &quot;3% a year&quot; occurrence. Furthermore it appears
          that risk representations are not neutral: they cause risk taking even when
        they are known to be unreliable.</font>                </p></td>
    </tr>
  </table>
  <hr align="center" width="525" size="1" />
  <table width="525" border="0" cellspacing="2" cellpadding="5">
    <tr>
      <td><strong><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Technical Appendix to &quot;The Fourth Quadrant&quot;—<a href="http://www.fooledbyrandomness.com/EDGE/index.html" target="new">Click Here</a> </font></strong></td>
    </tr>
  </table>
  <hr align="center" width="525" size="1" />
  <table width="525" border="0" cellspacing="2" cellpadding="5">
    <tr>
      <td width="528"><div align="center">
        <p><img src="../../indexelements/banner_realityclub.gif" width="500" height="50" /></p>
        <p align="left"><strong><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><a href="/discourse/fourth_quadrant.html">On &quot;THE FOURTH QUADRANT: A MAP OF THE LIMITS OF STATISTICS&quot; </a></font></strong><font size="2" face="Verdana, Arial, Helvetica, sans-serif"><strong><br />
By Nassim Nicholas Taleb</strong></font></p>
        <p align="left"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">Jaron Lanier, George Dyson</font></p>
        <p align="right"><a href="/discourse/fourth_quadrant.html"><font size="2" face="Verdana, Arial, Helvetica, sans-serif">...</font></a></p>
      </div></td>
    </tr>
  </table>
  <div align="center">
    <hr align="center" width="525" size="1" />
  </div>
  <div align="center">
    <table width="525" border="0" cellspacing="0" cellpadding="2">
      <tr valign="middle" bgcolor="#CCCCCC" align="center">
        <td><div 
align="center">
            <div align="center">
              <p><font color="#000000"
size="1" face="Verdana, Arial, Helvetica, sans-serif"><a 
href="/3rd_culture/bios/brockman.html"><b>John Brockman, </b></a></font><b><font face="Verdana, Arial, Helvetica,
sans-serif" size="1" color="#000000"> Editor and Publisher<br />
                      <a
href="/3rd_culture/bios/weinberger.html">Russell Weinberger</a>, Associate Publisher</font></b><font face="Verdana, Arial, Helvetica, sans-serif" size="1"
color="#000000"><br />
                      </font><font color="#FF0000"
size="1" face="Verdana, Arial, Helvetica, sans-serif"><a 
href="mailto:editor@edge.org">contact: editor@edge.org</a></font><font face="Verdana, Arial, Helvetica,
sans-serif" size="1" color="#000000"><br />
                        Copyright &copy; 2008 By </font><font color="#000000" size="1"
face="Verdana, Arial, Helvetica, sans-serif"><a
href="/about_edge.html">Edge Foundation, Inc</a></font><font face="Verdana, Arial, Helvetica,
sans-serif" size="1"
color="#000000"><br />
                          All Rights Reserved. </font></p>
            </div>
        </div></td>
      </tr>
      <tr
valign="top">
        <td height="17"><div align="center">
            <p> <font color="#FFFFFF" 
face="Verdana, Arial, Helvetica, sans-serif"><font color="#000000" size="1">[<a href="#top">top</a>]</font></font></p>
          </div></td>
      </tr>
    </table>
  </div>
</div>
</body>
</html>
